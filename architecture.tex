\section{Architectures}
Classical games like chess or tic-tac-toe are usually ``solved'' by AIs using a
single approach and searching through a single tree of game states, though
usually by optimizing the search and tree in various ways.

In comparison most approaches to AIs playing real-time strategy games usually
have to use domain knowledge do further subdivide the problem of playing the
game, because of the fine-grained simulations involved, and the various levels
of abstraction that is needed to get a successful AI. And especially when
approaching the way humans think about a problem more complex architectures
are needed.

\subsection{Decomposition of problem}
Michael Buro in his 2003 call for research \cite{buro2003rts} identified six
important sub-problems in real-time strategy games that he said would be
interesting for AI research to focus on:

\begin{description}
  \item [Resource management.] To be able to build up an army one needs to gather
    resources, and the balance between gathering resources (by creating workers),
    building an army and evolving through the technology tree is an important
    part of the macro/high-level strategy.
  \item [Decision making with uncertainty.] Because of fog of war, there is a
    high degree of uncertainty involved in the decision making. Therefore the AI
    needs to create hypotheses and act according to them, and should scout to
    confirm these.
  \item [Spatial and temporal reasoning.] Analyzing and predicting spatially as
    well as temporarily. Identifying choke points and predicting outcomes and
    utilities of actions it takes are some obvious applications.
  \item [Collaboration.] In most RTSes it is possible for players to ally, and
    how to share intelligence and coordinate attacks is a challenging problem,
    though maybe not as interesting yet.
  \item [Opponent modelling.] Learning from the opponent is an important skill,
    and exploting the weaknesses of your opponent is an important aspect of
    human-level playing.
  \item [Adverserial real-time planning.] Abstracting away micro-level
    management to allow for more efficient search in the game state-space, and
    translate the found solutions back, is an important problem to solve.
\end{description}

A lot of research as been done into AIs for RTSes since this, however, and the
list might be a bit outdated. For example, one important aspect of most AIs
today is the micro-management of units, trying to maximize the utility of them 
(maximizing output of resource gatherers and damage dealt by offensive units,
for example).

Another important problem that is under-valued by the above list is learning
from existing knowledge, like learning build-orders from replays of games played
by humans (or other bots, though the utility of that might not be substantial).
This can be integrated into several of the items above, for example the decision
with uncertainty by statistically inferring the most probable states by
learning from earlier games.

A more general and simplified breakdown of the problem of playing Starcraft can
be found in Ben Weber's presentation from the AIIDE 2010 StarCraft AI
Competition:\cite{weber2010aiide}

\begin{description}
  \item [Managing economy] is the same as the resource management mentioned
    above, and is about getting a steady income.
  \item [Expanding the tech tree] to get more powerful and varied units.
  \item [Producing units] is perhaps one of the most complex parts. This
    involves both buildings and movable units, defensive and offensive.
  \item [Attack opponent] usually is not a very explicit action, but can still
    be pretty complex, since one needs to evaluate its own state against what
    it knows about the opponent to know when to attack, and where. This point
    also involves micro-management, which has received a lot of attention from 
    authors of AIs that have ranked highly.
\end{description}

Solving all of the aforementioned problems by themselves are what is the focus
of most research today, but another important problem is tying all of these
solutions together again. This is perhaps one of the most basic, but important,
aspects of the architecture. There are several different ways of doing this,
and some of the most common one is simply sharing a large amount of information
between sub-units in the architecture (for example a black-board based
architecture), or simply having a well-defined graph hierarchy where decisions
are propagated.

\subsection{Hierarchical architectures}
Hierarchical architectures rely on one or more levels of subsumption of
responsibility in a hierarchy of modules to tie together the various partial
solutions to the sub-problems stated earlier.

\subsubsection{BTHAI}
Two-layered hierarchy of separate sub-modules, separating areas of
responsibility into macro- and micro-management. The macro-level modules are
directly responsible for managing the micro-level modules.

\subsubsection{BroodwarBotQ}
Also separates the hierarchy of modules into two levels for micro- and
macro-level management. Instead of letting any of those layers dictate any of
the other, however, it has an arbitrator on top of the hierarchy, that meddles
between the other modules.

\subsubsection{Skynet}
Three-layered architecture, with high-level modules on top, issueing commands
to the modules in the tactics-level, who in turn dispatch tasks to a task
manager which hands the tasks of to the appropriate low-level
(micro-manageing) task handler.

\subsubsection{SPAR}
High-level modules decide which strategies to implement and abstract actions
are dispatched from the module responsible for tactical decisions, while
lower-level modules resolve and execute the detailed steps needed for the
abstract actions.

\subsection{Blackboard Architectures}
Blackboard architectures don't necessarily need a hierarchy of modules, each
module is responsible for interpreting the data in the shared memory itself,
and putting back out the results of processing (if any).

\subsubsection{Nova}
It has three sets of modules; a set of micro-management modules for handling
individual actions, a set of macro-management modules for handling higher-level
planning, economy and production, and finally a single ``strategy manager''
module that is responsible for selecting strategies.

\subsection{Cognitive Architectures}
Cognitive architectures are architectures that base themselves on some model of
human cognition. There are several competing models of cognition, and one of
the most recent and well-supported is the Global Workspace Theory.

There currently have been no attempts at utilizing cognitive models for playing
Starcraft: BroodWar.

\subsection{Models of cognition}
A cognitive model is an approximation of how cognitive processes work. They are
often used for understanding how humans take decisions, and predict 

\subsection{Global Workspace Theory}

Global Workspace Theory is a model of cognition that is very well supported
by experimental data and has been used to implement processes that imitate
human decision making (for example for solving the problem of assigning
people to jobs in the US Navy). 

It is based around an understanding of the brain as a set of many more or less
independent modules, working together by utilizing a shared workspace (hence the
``global workspace''), and cycles of the various submodules competing for a
space in this shared workspace.\cite{baars2005gwd}

\subsection{Cognitive Models in game AIs}
There have been several more or less successful attempts at implementing models
of cognition into game-playing agents. One of the more recent ones is
CERA-CRANIUM.


\subsection{CERA-CRANIUM}
CERA-CRANIUM intends to implement a general architecture for game-playing
agents based on various cognitive architectures, and not tied to any specific
model of cognition. It has already been used to implement a bot that plays
Unreal Tournament 2004 (a first-person shooter game) using a model based on the
Global Workspace Theory. \cite{Arrabales2009}

It is based on two major modules:
\begin{description}
 \item [CRANIUM] (Cognitive Robotics Architecture Neurologically Inspired
Underlying Manager) is a tool to create and manage a large amount of
simultanous processes interacting through a shared workspace.
 \item [CERA] (Conscious and Emotional Reasoning Architecture)
 utilizes CRANIUM to create a dynamic control architecture structured in
layers, based on computational models of consciousness.
\end{description}

\subsubsection{CRANIUM}
CRANIUM is basically a software library that can execute thousand of parallel
but coordinated processes.

\subsubsection{CERA}
CERA is based around four layers; the sensory-motor services, physical layer,
mission-specific layer and the core layer, based on the services provided by
CRANIUM.

The sensory-motor layer is the most basic, and lowest-level layer, which
provides a uniform interface for sensory input and motoric actuation, physical
or simulated. Each sensor and motor has a service in this layer.

The physical layer wraps the sensory-motor layer, doing some pre-processing of
the sensory data, checking that actuator commands are within safety limits,
etc. It doesn't do semantic information binding, only simple, ``dumb''
pre-processing, though.

The mission-specific layer processes the data from the physical layer,
according to the current missions and sub-goals of those missions, as well as
vital behaviour of the bot (the inherent goals). The strict layering means that
this layer can be modified indendently of the other layers, to account for
various needs depending on the assigned tasks, and accounting for functional
integrity.

The core layer is the highest level, and perform higher cognitive functions,
and it is this layer that is adjusted to implement various cognitive
architectures. It has five core modules, however; attention, status assessment,
preconscious management, memory management and self-coordination. While these
are defined as core modules in CERA, the modular design means that they can be
replaced by a custom set.

The physical and mission-specific layers are inspired by cognitive models of
consciousness, where the various modules compete and collaborate in a shared
workspace. In CERA there is two workspaces; one for searching for the solution
to ``what must be the next content of the agent's conscious perception?'' and
``what must be the next action to execute?''. This differs from traditional AI
control architectures where one only attempts to find the best solution to the
second question, and ignoring the first. \cite{Arrabales2009} argues that to
successfully answer the second question in a human-like fashion, you first need
to answer the first one.